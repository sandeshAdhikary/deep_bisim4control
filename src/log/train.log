{"episode_reward": 0.0, "episode": 1.0, "duration": 54.728089570999146, "step": 250}
{"episode_reward": 17.207355292723175, "episode": 2.0, "duration": 1.8709630966186523, "step": 500}
{"episode_reward": 16.600309758058792, "episode": 3.0, "duration": 1.8026282787322998, "step": 750}
{"episode_reward": 12.502835683998796, "episode": 4.0, "duration": 1.8279666900634766, "step": 1000}
{"episode_reward": 7.463008726120952, "episode": 5.0, "batch_reward": 0.05311825178605351, "critic_loss": 0.012942199849167927, "ae_transition_loss": 0.013826643544323522, "ae_encoder_loss": 0.0005607848736233643, "actor_loss": -0.16304451466036307, "actor_target_entropy": -6.0, "actor_entropy": 5.613057076718883, "alpha_loss": 0.043658794998232726, "alpha_value": 0.00661189949575705, "duration": 176.49634265899658, "step": 1250}
{"episode_reward": 5.913095536619892, "episode": 6.0, "batch_reward": 0.04735793755948543, "critic_loss": 0.013139835849404336, "ae_transition_loss": 0.006125627933070064, "ae_encoder_loss": 0.0010055550893303007, "actor_loss": -0.5631705439090728, "actor_target_entropy": -6.0, "actor_entropy": 3.986902097702026, "alpha_loss": 0.00933670099452138, "alpha_value": 0.0047653909722488764, "duration": 34.52348256111145, "step": 1500}
{"episode_reward": 9.388432202666827, "episode": 7.0, "batch_reward": 0.04466396841406822, "critic_loss": 0.005650667758658528, "ae_transition_loss": 0.0037936814269050956, "ae_encoder_loss": 0.0007314322262536734, "actor_loss": -0.622275595664978, "actor_target_entropy": -6.0, "actor_entropy": 3.4194575672149656, "alpha_loss": 0.00811145225726068, "alpha_value": 0.00464211185571673, "duration": 35.08982276916504, "step": 1750}
{"episode_reward": 7.297131743070933, "episode": 8.0, "batch_reward": 0.0426232902109623, "critic_loss": 0.04646131987310946, "ae_transition_loss": 0.012313909349963069, "ae_encoder_loss": 0.0007356706674327142, "actor_loss": -0.6824119629859924, "actor_target_entropy": -6.0, "actor_entropy": 3.9268571796417238, "alpha_loss": 0.0011929420437663794, "alpha_value": 0.0045216075550999135, "duration": 34.812628507614136, "step": 2000}
{"episode_reward": 6.990886322299002, "episode": 9.0, "batch_reward": 0.04098641356825829, "critic_loss": 0.0279446301497519, "ae_transition_loss": 0.005187779289670289, "ae_encoder_loss": 0.0007213197709061205, "actor_loss": -0.8030666847229004, "actor_target_entropy": -6.0, "actor_entropy": 5.498085797309876, "alpha_loss": 0.006358307758579031, "alpha_value": 0.004509174817099925, "duration": 34.36571979522705, "step": 2250}
{"episode_reward": 8.847701005159236, "episode": 10.0, "batch_reward": 0.04023318532109261, "critic_loss": 0.013603596340864896, "ae_transition_loss": 0.004237751013599336, "ae_encoder_loss": 0.0007791133583523333, "actor_loss": -0.9388342576026917, "actor_target_entropy": -6.0, "actor_entropy": 4.110358997344971, "alpha_loss": 0.0022723698640475048, "alpha_value": 0.004439025362805374, "duration": 34.33332419395447, "step": 2500}
{"episode_reward": 7.697188280791742, "episode": 11.0, "batch_reward": 0.04087300661206245, "critic_loss": 0.00855722126364708, "ae_transition_loss": 0.00290582992695272, "ae_encoder_loss": 0.0005988688933430239, "actor_loss": -1.100541434764862, "actor_target_entropy": -6.0, "actor_entropy": 2.230164160728455, "alpha_loss": 0.002705582996364683, "alpha_value": 0.004372602026207876, "duration": 84.45529222488403, "step": 2750}
{"episode_reward": 10.453539790123775, "episode": 12.0, "batch_reward": 0.03929343259334564, "critic_loss": 0.04416088615357876, "ae_transition_loss": 0.008987828567624092, "ae_encoder_loss": 0.0006722225897829048, "actor_loss": -1.1861590671539306, "actor_target_entropy": -6.0, "actor_entropy": 3.435360682964325, "alpha_loss": 0.004774789923219941, "alpha_value": 0.00431930204317171, "duration": 34.20852279663086, "step": 3000}
{"episode_reward": 4.680152904898385, "episode": 13.0, "batch_reward": 0.03888281288743019, "critic_loss": 0.010780606605112552, "ae_transition_loss": 0.0029095810409635304, "ae_encoder_loss": 0.0006046888346318155, "actor_loss": -1.287275507926941, "actor_target_entropy": -6.0, "actor_entropy": 2.6991913089752195, "alpha_loss": 0.004728003141470254, "alpha_value": 0.0042038010389472795, "duration": 34.267322301864624, "step": 3250}
{"episode_reward": 9.089082180930264, "episode": 14.0, "batch_reward": 0.03835867059230805, "critic_loss": 0.007074377549812197, "ae_transition_loss": 0.0023042811029590667, "ae_encoder_loss": 0.0004309160567354411, "actor_loss": -1.4143087568283081, "actor_target_entropy": -6.0, "actor_entropy": 2.6584650211334226, "alpha_loss": 0.0011751219137222505, "alpha_value": 0.004128296084322023, "duration": 34.325138330459595, "step": 3500}
{"episode_reward": 7.8728882791062915, "episode": 15.0, "batch_reward": 0.038010610409080985, "critic_loss": 0.0062971763741225, "ae_transition_loss": 0.0021964520667679607, "ae_encoder_loss": 0.00041063478332944216, "actor_loss": -1.5065486974716187, "actor_target_entropy": -6.0, "actor_entropy": 2.8124305152893068, "alpha_loss": 9.660520742181688e-05, "alpha_value": 0.004117594322491316, "duration": 34.31458616256714, "step": 3750}
{"episode_reward": 9.268641485569747, "episode": 16.0, "batch_reward": 0.04322066979110241, "critic_loss": 0.007903714096173645, "ae_transition_loss": 0.0025494159273803233, "ae_encoder_loss": 0.0009470316848019138, "actor_loss": -1.609259994506836, "actor_target_entropy": -6.0, "actor_entropy": 2.739854963302612, "alpha_loss": -0.00013362772506661714, "alpha_value": 0.004120780190001144, "duration": 34.418232917785645, "step": 4000}
{"episode_reward": 32.739162036278216, "episode": 17.0, "batch_reward": 0.04692698495090008, "critic_loss": 0.007324045235291124, "ae_transition_loss": 0.0030290663074702025, "ae_encoder_loss": 0.0017251809511799365, "actor_loss": -1.7238451614379884, "actor_target_entropy": -6.0, "actor_entropy": 2.7692133769989016, "alpha_loss": -0.0017021805928088725, "alpha_value": 0.00414509170658606, "duration": 34.338095903396606, "step": 4250}
{"episode_reward": 34.65846522591584, "episode": 18.0, "batch_reward": 0.05657069143652916, "critic_loss": 0.026554349226877095, "ae_transition_loss": 0.005917771948501468, "ae_encoder_loss": 0.0049510450437664985, "actor_loss": -1.809110300064087, "actor_target_entropy": -6.0, "actor_entropy": 4.1397783584594725, "alpha_loss": -0.006640864543733187, "alpha_value": 0.00422160239394914, "duration": 34.34625315666199, "step": 4500}
{"episode_reward": 91.96550641916919, "episode": 19.0, "batch_reward": 0.07588990972936153, "critic_loss": 0.03197169102728367, "ae_transition_loss": 0.008489563405513764, "ae_encoder_loss": 0.009903461521491408, "actor_loss": -2.0850938835144044, "actor_target_entropy": -6.0, "actor_entropy": 4.159848978042603, "alpha_loss": -0.014362211298197508, "alpha_value": 0.0045917954559087214, "duration": 34.447434425354004, "step": 4750}
{"episode_reward": 102.80402574656144, "episode": 20.0, "batch_reward": 0.08805009481310845, "critic_loss": 0.09114361946284771, "ae_transition_loss": 0.012946850948035717, "ae_encoder_loss": 0.013580756060779095, "actor_loss": -2.324100616455078, "actor_target_entropy": -6.0, "actor_entropy": 4.589861079335213, "alpha_loss": -0.022701733507215976, "alpha_value": 0.005225527626614111, "duration": 34.491332054138184, "step": 5000}
{"episode_reward": 36.85188905326827, "episode": 21.0, "batch_reward": 0.0877487604022026, "critic_loss": 0.03406536822021008, "ae_transition_loss": 0.013002853948622942, "ae_encoder_loss": 0.016214851800352335, "actor_loss": -2.5256196708679197, "actor_target_entropy": -6.0, "actor_entropy": 5.264749448776245, "alpha_loss": -0.01874732333794236, "alpha_value": 0.006030571880206462, "duration": 85.31296992301941, "step": 5250}
{"episode_reward": 8.637260218870468, "episode": 22.0, "batch_reward": 0.08415304398536683, "critic_loss": 0.028423820093274117, "ae_transition_loss": 0.012693651132285594, "ae_encoder_loss": 0.01782954416796565, "actor_loss": -2.582671184539795, "actor_target_entropy": -6.0, "actor_entropy": 5.36047966003418, "alpha_loss": -0.005513907692627981, "alpha_value": 0.006568308103208569, "duration": 35.3647186756134, "step": 5500}
{"episode_reward": 7.352682730247374, "episode": 23.0, "batch_reward": 0.08622682505846023, "critic_loss": 0.029218629874289036, "ae_transition_loss": 0.012827650398015976, "ae_encoder_loss": 0.018699203979223967, "actor_loss": -2.634377878189087, "actor_target_entropy": -6.0, "actor_entropy": 4.884583259582519, "alpha_loss": 0.00044431885809171945, "alpha_value": 0.006616852882884115, "duration": 34.51565766334534, "step": 5750}
{"episode_reward": 40.85526427513055, "episode": 24.0, "batch_reward": 0.086925518989563, "critic_loss": 0.028322321727871896, "ae_transition_loss": 0.013476732939481735, "ae_encoder_loss": 0.019622451107949017, "actor_loss": -2.7486461849212644, "actor_target_entropy": -6.0, "actor_entropy": 4.917393013000488, "alpha_loss": -0.005029563751071692, "alpha_value": 0.0067626759581156885, "duration": 34.52745175361633, "step": 6000}
{"episode_reward": 18.501793661801315, "episode": 25.0, "batch_reward": 0.08468434488773346, "critic_loss": 0.023452158212661743, "ae_transition_loss": 0.011421759989112615, "ae_encoder_loss": 0.021670932434499263, "actor_loss": -2.8019400386810305, "actor_target_entropy": -6.0, "actor_entropy": 5.184044902801514, "alpha_loss": 0.00041987073759082704, "alpha_value": 0.006954658457492526, "duration": 34.577497720718384, "step": 6250}
{"episode_reward": 5.344953118344157, "episode": 26.0, "batch_reward": 0.08245130610466003, "critic_loss": 0.026507626220583915, "ae_transition_loss": 0.01134057313017547, "ae_encoder_loss": 0.020915378354489804, "actor_loss": -2.806850339889526, "actor_target_entropy": -6.0, "actor_entropy": 5.700119445800781, "alpha_loss": 0.011890381779521704, "alpha_value": 0.006638593909408547, "duration": 34.892269134521484, "step": 6500}
{"episode_reward": 10.758801276647535, "episode": 27.0, "batch_reward": 0.08376676888763905, "critic_loss": 0.03335280943661928, "ae_transition_loss": 0.01568968426808715, "ae_encoder_loss": 0.027360952366143464, "actor_loss": -2.8679680824279785, "actor_target_entropy": -6.0, "actor_entropy": 5.678093029022217, "alpha_loss": 0.003766210919711739, "alpha_value": 0.006093766580978252, "duration": 35.324395179748535, "step": 6750}
{"episode_reward": 40.94677211047991, "episode": 28.0, "batch_reward": 0.08967138540744782, "critic_loss": 0.03531495648622513, "ae_transition_loss": 0.017419535271823407, "ae_encoder_loss": 0.0382533713132143, "actor_loss": -3.0142166423797607, "actor_target_entropy": -6.0, "actor_entropy": 5.412039169311523, "alpha_loss": -0.00034491882263682785, "alpha_value": 0.006054719714072215, "duration": 34.85922050476074, "step": 7000}
{"episode_reward": 81.40838007267644, "episode": 29.0, "batch_reward": 0.0951095541715622, "critic_loss": 0.035287864841520786, "ae_transition_loss": 0.01656992457807064, "ae_encoder_loss": 0.04150779685378075, "actor_loss": -3.1557016277313235, "actor_target_entropy": -6.0, "actor_entropy": 5.417151725769043, "alpha_loss": -4.8440989572554823e-05, "alpha_value": 0.0060625021180105544, "duration": 34.615835428237915, "step": 7250}
{"episode_reward": 36.00818125851075, "episode": 30.0, "batch_reward": 0.0967836020886898, "critic_loss": 0.03651897399872541, "ae_transition_loss": 0.017366135954856872, "ae_encoder_loss": 0.04307330803573132, "actor_loss": -3.270668640136719, "actor_target_entropy": -6.0, "actor_entropy": 5.585282203674317, "alpha_loss": 0.0020277097723446786, "alpha_value": 0.005992569026724993, "duration": 34.64239454269409, "step": 7500}
{"episode_reward": 59.59207849026156, "episode": 31.0, "batch_reward": 0.1029126839339733, "critic_loss": 0.04143261682242155, "ae_transition_loss": 0.01797898427769542, "ae_encoder_loss": 0.04436724079400301, "actor_loss": -3.428354648590088, "actor_target_entropy": -6.0, "actor_entropy": 5.491987140655517, "alpha_loss": -0.005972649080562406, "alpha_value": 0.005977097007448602, "duration": 83.78005337715149, "step": 7750}
{"episode_reward": 78.81934083605296, "episode": 32.0, "batch_reward": 0.1111185844540596, "critic_loss": 0.04368217361718416, "ae_transition_loss": 0.01835962149873376, "ae_encoder_loss": 0.05048801686614752, "actor_loss": -3.5731688537597655, "actor_target_entropy": -6.0, "actor_entropy": 5.422869190216065, "alpha_loss": -0.006667292949510738, "alpha_value": 0.006533711132006033, "duration": 34.483556032180786, "step": 8000}
{"episode_reward": 90.81732598755231, "episode": 33.0, "batch_reward": 0.11524593934416771, "critic_loss": 0.04197287359833717, "ae_transition_loss": 0.017902180407196284, "ae_encoder_loss": 0.04881287394464016, "actor_loss": -3.749838596343994, "actor_target_entropy": -6.0, "actor_entropy": 5.693297954559326, "alpha_loss": 0.004316639668075368, "alpha_value": 0.006663192132047161, "duration": 34.55770254135132, "step": 8250}
{"episode_reward": 20.67012900857308, "episode": 34.0, "batch_reward": 0.11716022923588752, "critic_loss": 0.056221750266849994, "ae_transition_loss": 0.019213318750262262, "ae_encoder_loss": 0.047771343283355236, "actor_loss": -3.9012275619506838, "actor_target_entropy": -6.0, "actor_entropy": 5.692009769439697, "alpha_loss": 0.0004532361023593694, "alpha_value": 0.006445020947210015, "duration": 34.53640031814575, "step": 8500}
{"episode_reward": 91.95542174126027, "episode": 35.0, "batch_reward": 0.12346617412567139, "critic_loss": 0.054666136294603346, "ae_transition_loss": 0.01829808523133397, "ae_encoder_loss": 0.051038700610399244, "actor_loss": -4.076947267532349, "actor_target_entropy": -6.0, "actor_entropy": 5.570419532775879, "alpha_loss": 0.00019115912262350322, "alpha_value": 0.006460325267686046, "duration": 34.84474849700928, "step": 8750}
{"episode_reward": 85.82637393379213, "episode": 36.0, "batch_reward": 0.1277395775914192, "critic_loss": 0.05700178192555904, "ae_transition_loss": 0.0183403109125793, "ae_encoder_loss": 0.050499975502490996, "actor_loss": -4.272813289642334, "actor_target_entropy": -6.0, "actor_entropy": 5.414962478637696, "alpha_loss": -0.005311845862539485, "alpha_value": 0.0065270445577973206, "duration": 34.67045617103577, "step": 9000}
{"episode_reward": 19.39815406405205, "episode": 37.0, "batch_reward": 0.128883429646492, "critic_loss": 0.06891743834316731, "ae_transition_loss": 0.020499457612633706, "ae_encoder_loss": 0.05384352372586727, "actor_loss": -4.439374004364014, "actor_target_entropy": -6.0, "actor_entropy": 5.375890701293946, "alpha_loss": -0.009129014726728201, "alpha_value": 0.007203628994343097, "duration": 34.503007888793945, "step": 9250}
{"episode_reward": 79.9546286267784, "episode": 38.0, "batch_reward": 0.13483113560080529, "critic_loss": 0.06310863914340735, "ae_transition_loss": 0.01820709150657058, "ae_encoder_loss": 0.051276946112513544, "actor_loss": -4.584909248352051, "actor_target_entropy": -6.0, "actor_entropy": 5.452150798797607, "alpha_loss": -0.01665472171921283, "alpha_value": 0.00851279260410443, "duration": 34.496636629104614, "step": 9500}
{"episode_reward": 65.86381867138603, "episode": 39.0, "batch_reward": 0.13773503962159156, "critic_loss": 0.07384150332212448, "ae_transition_loss": 0.02001221527159214, "ae_encoder_loss": 0.05588638724386692, "actor_loss": -4.682091449737549, "actor_target_entropy": -6.0, "actor_entropy": 5.746168327331543, "alpha_loss": 0.004470440953969955, "alpha_value": 0.009594253190953448, "duration": 34.50263214111328, "step": 9750}
{"episode_reward": 66.53379880167823, "episode": 40.0, "batch_reward": 0.14105195835232734, "critic_loss": 0.07626990416646004, "ae_transition_loss": 0.02047016740962863, "ae_encoder_loss": 0.054521473810076715, "actor_loss": -4.842803302764892, "actor_target_entropy": -6.0, "actor_entropy": 5.690932189941406, "alpha_loss": 0.0016530447250697761, "alpha_value": 0.008868109240203263, "duration": 34.50176215171814, "step": 10000}
