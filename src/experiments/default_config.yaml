# Defaults from DBC paper
replay_buffer_capacity: 100_000 # paper used 1M, but we don't have memory
batch_size: 128
discount: 0.99
critic_lr: 0.0001
critic_target_update_freq: 2
critic_tau: 0.005
actor_lr: 0.0001
actor_update_freq: 2
actor_log_std_max: 2
actor_log_std_min: -5
encoder_lr: 0.0001
decoder_lr: 0.0001
init_temperature: 0.1
encoder_feature_dim: 50
transition_model_type: 'probabilistic'
# Other defaults
action_repeat: 1
actor_beta: 0.9
agent: bisim
alpha_beta: 0.9
alpha_lr: 0.001
bisim_coef: 0.5
boxed_env: false
config: null
critic_beta: 0.9
decoder_type: pixel
decoder_update_freq: 1
decoder_weight_lambda: 0.000001
distraction_level: 0.2
distractor: None
distractor_img_shrink_factor: 1.3
distractor_type: None
domain_name: cheetah
encoder_kernel_bandwidth: auto
encoder_mode: spectral
encoder_normalize_loss: true
encoder_ortho_loss_reg: 0.0001
encoder_output_dim: null
encoder_stride: 1
encoder_tau: 0.005
encoder_type: pixel
episode_length: 500
eval_freq: 10000
eval_img_sources: null
eval_resource_files: null
frame_stack: 3
hidden_dim: 256
image_size: 88
img_source: null
init_steps: 1000
k: 3
levelset_factor: 1.0
load_encoder: null
dir: /project/logdir
logger: wandb
logger_img_downscale_factor: 3
logger_minimal: false
logger_project: misc
logger_tags: null
logger_video_log_freq: null
num_eval_envs: 1
num_eval_episodes: 20
num_filters: 32
num_layers: 4
num_seeds: 1
num_train_envs: 1
num_train_steps: 1_000_000
port: 2000
render: false
resource_files: null
reward_decoder_num_rews: 1
reward_decomp_method: eigenrewards
save_buffer: false
save_model: false
save_tb: false
save_video: false
seed: 1
sweep_config: null
task_name: run
total_frames: 1000
use_cagrad: false
vec_reward_from_model: false
work_dir: workdir
save_model_mode: None

